[{"title":"通过behave学习BDD","date":"2020-12-30T13:04:57.000Z","path":"/posts/e6f54ca7/","text":"前言最近觉得学习一个东西最好的方式就是使用它, 把抽象的东西变得具体而实际(ps:这好像刚好也是行为驱动开发存在的原因😄), 所以, 直接从pyhon的BDD工具behave着手, 感受BDD的逻辑和好处. 实例化需求的定义: 维基百科: Specification by example (SBE) is a collaborative approach to defining requirements and business-oriented functional tests for software products based on capturing and illustrating requirements using realistic examples instead of abstract statements. It is applied in the context of agile software development methods, in particular behavior-driven development. 实例化需求就是使用具体的例子来澄清需求和基于业务功能测试的一种协作方式. 实践方式通常为敏捷开发的行为驱动开发. 行为驱动开发的定义 On the “Agile specifications, BDD and Testing eXchange” in November 2009 in London, Dan North gave the following definition of BDD: BDD is a second-generation, outside–in, pull-based, multiple-stakeholder, multiple-scale, high-automation, agile methodology. It describes a cycle of interactions with well-defined outputs, resulting in the delivery of working, tested software that matters. 行为驱动开发就是使用一种通用的语言来描述验收条件的一些操作及被测程序对应的响应行为, 并由此自动验证代码的一种开发方法. 其中的通用语言一般使用Gherkin语言, 它基于领域驱动设计, 重点在于描述需求背景和目的, 让代码实现始终为需求服务.而自动化验证则是为了提供及时的反馈和回归测试. behave基本使用 python中常用的驱动框架有lettuce和behave, 但是lettuce不兼容python3.而Django也有对应的插件behave-django, 以下操作都是基于behave-django来实现的.步骤 安装behave-django1pip install behave-django settings.py文件中添加该插件1INSTALLED_APPS += ['behave_django'] 1) 项目的根目录创建features目录2) .feature文件中就是用Gerkin语言写的各个行为场景3) environment.py会在执行用例前, 执行里面的代码, 一般全局的前置条件和后置条件的逻辑在这个文件中定义.4) 目录下再创建steps目录, steps下就是各种需求例子的实现逻辑代码. .feature文件的内容格式. 其中双引号引起来的内容会被提取作为变量的值 格式为 As-a /I want to/So that 的内容不会被执行, 重点在于使用者和需求的背景 Given/When/Then 分别描述用例的前置条件、操作和检查点1234567Feature: My blog As a vister I want to be able to see the header in the page So that I know it is the right page Scenario: I access my blog Given I access the url \"/blog/\" Then I see the header M.Y environment.py中的内容12345678910111213from selenium import webdriver# context为一个全局对象, behave运行的时候会给这个对象绑定很多属性, # 包括before_all(), before_feature(), …, after_all()等回调函数# 因此我们也可以\b给context绑定自定义属性, 如下, 就绑定了browser属性, 其引用指向创建的webdriver实例def before_all(context): # 谷歌浏览器配置对象 opt = webdriver.ChromeOptions() # 解决“chrome正受到自动测试软件的控制”信息栏显示 opt.add_experimental_option(\"useAutomationExtension\", False) opt.add_experimental_option(\"excludeSwitches\", ['enable-automation']) context.browser = webdriver.Chrome(options=opt, executable_path=\"./chromedriver\") context.browser.base_url = \"https://yummyisminer.xyz\" my_step.py中的内容. 主要是对feature文件中的given和then的实现 12345678910111213141516from behave import given, thenfrom commons.some_decorator import wait# \"{url}\" 就是对应feature中的\"/blog/\", 用花括号变量名来标识为变量, 而这里的url作为变量引用/blog/这个值@given(u'I access the url \"{url}\"')def step_impl(context, url): context.browser.get(context.browser.base_url+url)@then(u'I see the header {tex}')@waitdef step_impl(context, tex): context.test.assertIn( tex, context.browser.find_element_by_css_selector(\"h1\").text ) my_step.py文件中有用到wait这个装饰器, 主要逻辑就是10s内, 每隔0.5s重新执行一遍被装饰的函数.12345678910111213141516import timefrom selenium.common.exceptions import WebDriverExceptionMAX_WAIT = 10def wait(fun): def wrapped_fun(*args, **kwargs): start_time = time.time() while True: try: return fun(*args, **kwargs) except(AssertionError, WebDriverException) as e: if time.time() - start_time &gt; MAX_WAIT: raise e time.sleep(0.5) return wrapped_fun 执行场景用例1python manage.py behave 启发 暂时的理解: BDD主要就是用来澄清需求, 使业务、开发、测试三方对需求的理解都一致, 所以应该一般require文件部分的内容由业务人员编写, 用来限定验收条件, 然后大家针对这些验收条件进行评审, 发现模糊的描述, 确认各种“如果xxx, 就xxx”的情况, 接着测试人员可以基于require文件编写对应的操作和验证实现方法, 每开发一个功能, 都需要跑通这些验收用例, 提前并持续不断的提供反馈, 降低后期返工的概率. 后续如果我要给自动化测试扩展BDD功能的话, 首先因为BDD主要就是用来写一些基于业务逻辑的验收用例, 那用例就应该跟自动化测试框架分离, 也就是BDD的逻辑是单独写在一个项目. 所以, 就需要把自动化测试框架打包成可安装模块.然后实现了BDD项目中, 在用例实例方法里导入自动化测试框架这个模块, 然后调用相关的逻辑方法完成操作和验证. 项目打包的大致步骤 创建一个目录, init.py文件, 自动化框架项目拷贝到该目录下, 并创建setup.py, 如下配置1234567891011121314151617import setuptoolssetuptools.setup( name=\"autotestwithstub\", version=\"1.0.1\", # 添加非py的数据文件 # 列表中的每一个元组的第一个元素为数据文件将存储到的目录(相对于当前解释器安装的根目录)， 第二个元素为要添加的文件路径 data_files=[('lib/Configs', ['autotestwithstub/Configs/MyApp.ini','autotestwithstub/Configs/logging_conf.ini'])], # 将目录下找到的包(也就是有__init__.py文件的目录)都安装 packages=setuptools.find_packages(), include_package_data=True, author=\"ym\", author_email=\"xx@qq.com\", url=\"https://yummyisminer.xyz\", description=\"a autotest framework with stub web server\",) 开始打包, 执行命令之后会在项目下创建dist目录, dist目录下就会有对应的tar.gz和whl格式的安装包1python3 setup.py sdist bdist_wheel 在当前使用的python解释器安装目录下, 安装刚刚生成的模块1pip install dist/autotestwithstub-1.0.1-py3-none-any.whl 新项目中导入之前项目下的包, 调用对应的逻辑 参考资料","link":"","tags":[]},{"title":"socket 模拟收发HTTP包","date":"2020-12-29T10:30:15.000Z","path":"/posts/6178cbe6/","text":"网络中数据发送的过程 应用层中, 服务端创建server_socket, 并通过bind的系统调用绑定端口,再调用listen使server_socket变成被动socket, 然后调用accept在对应端口上阻塞并监听客户端的连接, 客户端也创建自己的client_socket, 通过connect系统调用, 发送syn包给服务端的server_socket, 数据先会到tcp发送缓冲中,如果已经建立好连接, 则客户端的client_socket调用系统调用的write方法, 把数据写到tcp发送缓冲中, 然后数据开始进入tcp/ip协议栈, 首先是tcp层组装数据包, 并得到引用这些数据的数据包描述符sk_buff, 然后sk_buff进入IP层, 再进入发送队列, 再进入网卡的环形缓冲区, 然后网卡驱动调用DMA引擎, 把数据从网卡通过网线发送出去 网络中数据接收的过程 数据到达服务端的网络接口, 先是检查数据包中的目的Mac地址跟网卡的Mac地址是否匹配, 然后数据达到网卡队列, 再进入网卡的环形缓冲区, 并封装成sk_buff, 网卡调用DMA引擎发起中断, 通知CPU把数据从环形缓冲区取走, 然后这些数据就以sk_buff的形式进入IP层, tcp层, 在tcp层如果这个数据包是请求连接的syn包, 那么会先放到tcp的半连接队列, 等收到ack包的时候, 才放到tcp的全连接队列, 然后进入tcp接收缓冲, 再到达应用层 python版服务端的简单实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071# coding=utf-8import socketimport threadingGREAT = \"\"\"great\"\"\"CONTENT_LENGTH = \"\"\"Content-Length: 5\"\"\"STATUS_CODE = \"200 OK\"SAMEORIGIN = \"\"\"X-Frame-Options: SAMEORIGIN\"\"\"CHARSET = \"\"\"Content-Type: text/plain; charset=utf-8\"\"\"BICRLF = \"\\r\\n\\r\\n\"CRLF = \"\\r\\n\"def main(): # 创建服务端的套接字 server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM) server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) # 绑定端口 server_socket.bind((\"\", 3344)) # 服务端套接字在端口3344监听 # backlog 为等待(半)连接队列中的最大连接数 server_socket.listen(128) while True: # 接收客户端连接，并得到一个新的socket与客户端进行通信 client_socket, addr = server_socket.accept() thread_1 = threading.Thread(target=send_datas, args=(client_socket,)) thread_1.start()def send_datas(client_socket): “”“ 接收客户端连接后, 发送数据 ”“” # 开启keep alive, 维持长连接 client_socket.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1) # 如果一直没有收到数据, 则每隔8秒给客户端发送keep alive的tcp链路检测包 # define TCP_KEEPALIVE 0x10 /* idle time used when SO_KEEPALIVE is enabled */ # https://github.com/apple/darwin-xnu/blob/0a798f6738bc1db01281fc08ae024145e84df927/bsd/netinet/tcp.h client_socket.setsockopt(socket.IPPROTO_TCP, 0x10, 8) # 接收数据，返回http格式的响应 while True: # 接收数据的长度 len_recv = 6148 request = client_socket.recv(len_recv) # recv接收到fin包之后，就马上响应ack了，而服务端的fin包需要close之后才会发 print(\"re \" + request.decode(\"utf-8\")) # 如果客户端那边调用close, 服务端接收到的数据长度为0, if request: content = input(\"what do u want to response?:: \") # 返回http格式的数据，只要格式符合http的格式，那么浏览器就会认为是一个http响应，从而能解析 response = \"HTTP/1.1 {}{}{}{}{}\". \\ format(STATUS_CODE+CRLF,CHARSET+CRLF,SAMEORIGIN+CRLF,CONTENT_LENGTH+CRLF+CRLF,content) # 发送数据，且编码跟服务器设置的一致 client_socket.send(response.encode(\"utf-8\")) else: # 没加内层while循环前， 没进入这里是因为关闭浏览器的时候，没有再次接收客户端发送来的数据 print(\"没数据了\") # 客户端调用close后，服务端马上响应一个ack，且读通道也关闭 # 而服务端还有写通道未关闭，写通道也关闭后，就会给客户端发fin包 # 或者直接close也可以, 区别在于close不会马上释放连接 client_socket.shutdown(socket.SHUT_WR) # client_socket.close() breakif __name__ == \"__main__\": main_thread = threading.Thread(target=main) main_thread.start() 客户端的实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283import socketimport threadingCOOKUE = '''Cookie: Idea-38dabdcb=1a3e1891-7313-4a6c-8141-c158de42e97'''LANGUAGE = '''Accept-Language: zh-CN,zh;q=0.8'''USER_AGENT = '''User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.101 Safari/537.36'''ACCEPT = '''Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'''CACHE_CONTROL_MAX_AGE = '''Cache-Control: max-age=0'''CONNECTION_KEEP_ALIVE = '''Connection: keep-alive'''HOST = '''Host: 192.168.0.101:8000'''PATH = '''/blog/'''# PATH = '''/blog/?date=yyy'''BICRLF = \"\\r\\n\\r\\n\"CRLF = \"\\r\\n\"CONTENT_LEN = \"Content-Length: \"send_flag = Truedef send_data(tcp_socket): while send_flag: len_msg = int(input(\"how many char do you wanna send? : \")) # 等待输入，如果comm为close，客户端关闭连接 # content为要发送的内容，req_med为请求的方法，分别以空格分隔 comm, content, req_med = input(\"comm :\").split(\" \") if req_med == \"p\": req_med = \"POST\" else: req_med = \"GET\" long_msg = content * len_msg # .encode(\"utf-8\") len_lmsg = str(len(long_msg)) # 要发送的数据 msg = (\"%s %s HTTP/1.1\" + CRLF + \"%s%s%s%s%s%s%s%s\") \\ % (req_med, PATH, HOST + CRLF + CONTENT_LEN + len_lmsg + CRLF, CONNECTION_KEEP_ALIVE + CRLF, CACHE_CONTROL_MAX_AGE + CRLF, ACCEPT + CRLF, USER_AGENT + CRLF, LANGUAGE + CRLF, COOKUE + BICRLF, long_msg) msg = msg.encode(\"utf-8\") if comm.find(\"close\") != -1: tcp_socket.shutdown(socket.SHUT_RDWR) # tcp_socket.close() elif comm.find(\"pass\") != -1: pass elif send_flag == False: return else: tcp_socket.send(msg)def recv_data(tcp_socket=None, len_recv=None): while True: recv = tcp_socket.recv(len_recv) if recv: global send_flag send_flag = True else: send_flag = False tcp_socket.shutdown(socket.SHUT_WR) return print(recv)def main(): while True: # 创建socket, 该socket对应一个打开文件和一个文件描述符 # 入参1为指定协议族, 因为有的系统不一定有实现tcp/ip协议, # 入参2为socket的类型, tcp就对应SOCK_STREAM, 因为建立连接后, 数据就像流一样在两端传输 tcp_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM) print(tcp_socket.fileno()) # 连接服务端 tcp_socket.connect((\"192.168.0.101\", 8000)) global send_flag send_flag = True # 接收数据的长度 len_recv = 6148 # 同步阻塞的recv操作， 改成用一个线程异步接收数据，实时检测服务端发来的fin包，收到就马上把send_flag改为false thread = threading.Thread(target=recv_data, args=(tcp_socket, len_recv)) thread.start() send_data(tcp_socket)if __name__ == \"__main__\": main() whireshark 抓包截图 如图, 客户端调用connect后, 发送请求与服务端建立连接的syn包, 包含一个客户端维护的序列号 服务端收到syn包后, 也回一个混合了syn和ack的数据包, 其中包含服务端维护的序列号, 而ack包是作为对客户端syn包的确认回应, 所以ack号则是客户端的序列号+1, 客户端收到服务端的syn+ack后, 再对该包确认回应而发送ack包, 此时序列号+1, ack号=服务端序列号+1, 三次握手后, 客户端和服务端之间建立一条流通道, 服务端的tcp接收缓冲区满了, 所以给客户端发送一个tcp window update的包, 然后客户端发送http协议格式的数据, 服务端接收到数据回一个ack的包, 由于距离tcp流通道的上一个数据包的时间已经满8秒了, 于是服务端给客户端发送keep-alive的tcp包, 客户端接收后马上回一个ack, 服务端继续发送http格式的响应, 客户端回ack… 最后, 客户端调用close后, 会给服务端发送fin包, 但由于上一个包是服务端发来的keep-alive ack包, 所以同时也会发送ack号为服务端发来的keep-alive ack包的序列号+1的ack, 服务端马上单独回一个ack, 发送fin包的前提是服务端也调用了close, 而close还需要关闭接收通道释放资源等, 耗时较长, 所以就先单独回一个ack, 服务端再发fin包, 而且为了防止客户端没收到前面的ack, 这个包里也包含一个ack, 最后客户端回一个ack, tcp连接通道完全断开","link":"","tags":[{"name":"协议","slug":"协议","permalink":"https://yummyisminer.xyz/blog/tags/%E5%8D%8F%E8%AE%AE/"},{"name":"python","slug":"python","permalink":"https://yummyisminer.xyz/blog/tags/python/"},{"name":"socket","slug":"socket","permalink":"https://yummyisminer.xyz/blog/tags/socket/"}]},{"title":"基于OpenCover的代码覆盖率测试","date":"2020-12-02T23:40:59.000Z","path":"/posts/8920367b/","text":"前言之前的工作中有用到OpenCover对项目中的Asp.Net站点、服务进行覆盖率测试, 现在重新整理下笔记. OpenCover简介： 一个用于.NET 2.0及以上应用程序的代码覆盖的开源命令行工具; 使用PDB文件提供序列信息，来确定dll文件中哪些代码行与源代码的每一行相关联，然后检测、插桩每个序列点以记录命中的行; 因此必须要有的是PDB文件以及可执行文件和程序集，应该在调试模式下构建测试中的应用程序。如果未找到PDB文件，则不会收集任何覆盖数据; 使用COM（组件对象模型）开发，检测程序profiler部分则使用c++; 使用mono.Cecil来分析分支或IL以确定在何处检测代码; OpenCover提供的指标有： 声明范围, 即已涵盖的行数。 方法覆盖范围，即涵盖了哪些方法。 分支覆盖范围, 即采取了哪些分支, 这与圈复杂度有关 OpenCover主要命令参数： -target： 应用程序可执行文件或服务名称的路径我的理解：就是配置将被测程序运行起来的程序或服务。大多用的NUnit。本文例子用的是IIS Express -filter： 应用于选择性地包括或排除coverage结果中的程序集和类的过滤器列表 默认选择所有的类和方法 使用PartCover语法，(+|-)[Assembly-Filter]Type-Filter。 例如，+[Open*]* 包括以Open开头的程序 -[*]Core.* 排除Core命名空间中的所有类型(跟程序集无关)。 如果未提供过滤器，+[*]*则会自动应用默认包含所有的过滤器。 -output： 输出XML文件的路径，如果为空，则将在当前目录中创建results.xml -register [：user] - 注册和取消注册代码覆盖率分析器 -targetargs： - 要传递给目标进程的参数（可指定被测程序的路径） -targetdir： - 目标目录的路径或PDB文件的备用路径如果-targetargs 已经指定了被测程序的路径，那么这里可作为查找PDB文件的依据。本文例子则作为查找PDB文件的路径用法 文档参考1 参考2 参考3 参考4 未使用OpenCover时，被测程序的正常运行流程： 使用OpenCover、ReportGenerator后，被测程序的运行流程： 1)命令行调用OpenCover.Console.exe 2)OpenCover使用SentrySdk收集崩溃报告 3)解析命令行中传入的参数（被测程序路径、要打印使用说明、是否启动服务、过滤信息等） 4)处理过滤器信息，如果命令行中未传-filter参数，则默认匹配分析所有的类和方法——&gt;创建性能计数器 5)得到输出xml报告的全路径 6)初始化封装了注入框架依赖的容器 7)创建文件句柄，后续将覆盖率信息写入文件中。如果已经存在覆盖率xml文件，则合并 8)启动覆盖率分析进程。注册分析器，调用OpenCover.Profiler.dll 9)启动托管被测代码的程序(IIS Express) 10)访问站点测试被测程序 11)关闭IIS Express, 得到运行结果同时，也得到xml覆盖率结果 12)ReportGenerator将xml转成HTML OpenCover和ReportGenerator的主要配置流程：以测试站点程序为例: 1)配置好OpenCover、ReportGenerator、被测程序的路径、IIS Express config的路径 2)执行配置好相关参数的CMD命令, 示例如下：1H:\\白盒测试\\Debug\\Opencover\\OpenCover.Console.exe -target:\"C:\\Program Files (x86)\\IIS Express\\iisexpress.exe\" -targetdir:\"D:\\被测站点\\xxx.xxx.com\\bin\" -targetargs:\"/site:xxx_bh.xxx.com /config:\\\"C:\\Users\\ym\\Documents\\IISExpress\\config\\applicationhost.config\\\"\" -register:ym -output:\"H:\\白盒测试\\xml_ym\\xxx_bh.xxx.com\\xxx_bh.xxx.com.xml\" 3)此时IIS Express已经启动，访问在通过IIS Express配置的站点，开始测试。 4)测试完成后，退出IIS Express，生成xml文件。 5)使用ReportGenerator生成HTML文档，CMD命令示例如下：1H:\\白盒测试\\Debug\\ReportGenerator\\ReportGenerator.exe -reports:H:\\白盒测试\\xml\\白盒测试.xml -targetdir:H:\\白盒测试\\xml\\html ReportGenerator概述： ReportGenerator用于将OpenCover，PartCover，Visual Studio或NCover生成的XML报告转换为各种格式的友好可读报告。 主要就是配置xml文件的路径和输出html的路径, 执行命令后, ReportGenerator就会解析传入的参数, 然后输出报告常用的命令行参数： -reports： - 应该解析的覆盖率报告，分号分隔，允许使用通配符 -targetdir： - 应保存生成的报告的目录 -sourcedirs：[;] [;] - 包含相应源代码的目录，可选，分号分隔 -classfilters：&lt;（+ | - ）filter&gt; [; &lt;（+ | - ）filter&gt;] [; &lt;（+ | - ）filter&gt;] - 报表中应包含或排除的类列表，可选，可用通配符。 如果是测试Windows服务的覆盖率：1）执行如下命令启动服务：G:\\Opencover所在路径\\OpenCover.Console.exe -service:byname -target:安装好的服务名 -register:ym -output:H:\\白盒测试保存路径\\xxx\\xxx.xml2）测试完毕后，正常关闭服务，则可收集覆盖数据。 报告部分截图 包含语句覆盖和分支覆盖情况。点击相应的页面，会进入对应程序，可看到具体覆盖到哪一行代码。 代码覆盖详情截图 绿色表示完全覆盖，橙色表示该行代码还有分支未覆盖到，红色则未覆盖。 文档中的描述 参考资料1 参考资料2 关于IIS Express： 一个兼具Visual Studio的ASP.NET开发服务器和Windows的IIS Web服务器功能的轻量级web服务器。具体描述 配置 为什么用IIS Express：更轻便, 易于实现自动化. 而结合实际需求，虽然也可以直接往-target传参为IIS的启动程序来进行监控测试情况，但是IIS还部署了其他非测试站点，会相互影响。所以实际应用还是采用IIS Express，每个测试人员部署自己的IIS Express，而不会相互影响。 启动完整的IIS的操作：1）在调试模式下运行被测程序并启动OpenCover（将代码构建到调试模式获取PDB文件）2）所有在站点下运行的应用程序都必须使用相同的应用程序池；否则，会报错3）在调试模式下启动被测程序前，需要停止intserver（启动被测程序的服务） 原文描述：Running against IIS12345678910111213141516171819Normally I’d suggest running against IISEXPPRESS as I think it is easier to automate. However for those who really want to run against a full blown IIS then the following instructions (supplied by a user) will hopefully suffice.“The trick is to start OpenCover to run the w3wp.exe process in debug mode e.g.OpenCover.Console.exe -target:C:\\Windows\\System32\\inetsrv\\w3wp.exe -targetargs:-debug -targetdir:C:\\Inetpub\\wwwwoot\\MyWebApp\\bin\\ -filter:+[*]* -register:userThere are some prerequisites though:1.All applications running under the site must make use of the same app pool; you'll get errors in the EventLog otherwise.2.inetserver needs to be stopped, before starting w3wp.exe in debug mode. You can use the following command:net stop w3svc /yAfter testing/code coverage completion you can close the w3wp.exe process and start the inetserver again:net start w3svcThis procedure was tested on a Win2008 machine with IIS7.5”You can also run multiple OpenCover instances against separate IIS sites by using the –s option when running IIS to choose the siteid e.g.OpenCover.Console.exe -target:C:\\Windows\\System32\\inetsrv\\w3wp.exe -targetargs:\"-debug -s 1\" -targetdir:%WebSite_Path% -filter:+[*]* -register:user -output:%CoverageResult_Path%Then you can use ReportGenerator to merge the coverage results. 关于PDB文件： PDB是Program Data Base 的缩写, 程序数据库（.pdb）文件（也称为符号文件）。 它将项目源代码中的标识符和语句映射为已编译应用程序中的相应标识符和指令。这些映射文件将调试器链接到您的源代码，从而可以进行调试, 跟踪到特定的函数和代码行。 它包含调试代码时所需的许多重要相关信息（在Visual Studio中），例如，在您希望调试器在Visual Studio中中断的位置插入断点。 当加载一个模块(dll文件), debugger找到对应的pdb(Program Debug Database)文件. 文件中记录了模块的变量、方法、类、源代码行数等信息, 包含类型和符号化调试信息编译和链接项目的过程中收集的二进制文件。参考1 参考2 参考3 参考4 FAQ:1）若提示 原因有三： （1）未走到相关代码（2）缺少对应的pdb文件（3）未正确注册Profiler，添加参数-register:账号名","link":"","tags":[{"name":"测试","slug":"测试","permalink":"https://yummyisminer.xyz/blog/tags/%E6%B5%8B%E8%AF%95/"},{"name":"覆盖率测试","slug":"覆盖率测试","permalink":"https://yummyisminer.xyz/blog/tags/%E8%A6%86%E7%9B%96%E7%8E%87%E6%B5%8B%E8%AF%95/"}]},{"title":"《猎豹行动》笔记","date":"2020-04-20T02:10:11.000Z","path":"/posts/5e8f1732/","text":"前言去年为了了解敏捷开发流程和DevOps, 也看了《猎豹行动》这本书. 同样按照, 故事脉络、相关概念、个人感悟这几个模块来整理笔记. 故事脉络 一家金融服务公司, 为了更快地响应业务部门的请求, 更好地交付业务价值, 启动名为“猎豹行动”的行动计划, 落实敏捷转型. 要解决的问题: 开发模式依然以瀑布模型为主, 交付慢且昂贵, 业务部门对此不满 业务部门架构复杂, 各自的利益与兴趣点不同, 难以形成统一的优先级和需求意见, 对IT部门有不同的请求 IT部门由于预算问题, 人员编制不足 流程烦琐、基础设施落后、自动化程度不足 PMO部门承担所有项目的甲方, 为了维护部门利益, 在所有项目中做中间人角色, 不愿IT部门直接解除其他业务部门(最终用户), 但又不愿承担PO的角色 猎豹行动启动方案: 组织全覆盖的敏捷扫盲班, 让所有IT同事对敏捷开发有基本的了解, 审视当前的交付模式并找出改进点. 分析当前的瀑布模型开发: 痛点 业务部门 逾期交付、超支、缺乏透明度，不知道具体进度、很难变更需求、看到成品时项目已接近尾声、最终发现开发出来的产品不是他们想要的、殆误战机，丢失市场机会 IT部门 过度承诺、难以一次性消化所有需求、惧怕需求变更、不断重做、后期压力巨大、加班 导致痛点的原因 只有预算和目标交付时间是确定的 不确定因素 范围和具体需求、可能的需求变更、人员（放假离职）、估算的准确性、对现有系统的影响、服务器环境的搭建 存在的问题 需求分析花的时间多，开发时间被压缩 变更成本高 业务要在用户验收测试阶段才能看到成品，临近目标交付日期, 才发现产品不合要求 介绍敏捷开发模式: 迭代开发就是敏捷开发最重要的特点. 软件开发最重要的是搞清楚用户到底想要什么. 以两组蒙娜丽莎的完成过程图为例, 如果客户任务蒙娜丽莎的头最重要, 那上面那组的第二幅图就可以交付. 跟每个团队进行交谈, 了解团队痛点, 探讨具体改进方案. 总结敏捷开发给业务部门和IT部门带来的好处, 并给出敏捷启动建议: 围绕已知的范围和需求定义用户故事和建立Product Backlog 为用户故事排优先级 商定Sprint的长度 商定Sprint计划会议和评审会议的日程 商定发布计划 准备相应的辅助工具 组织针对业务部门的敏捷基础培训, 配合落实敏捷转型. 通过“棉花糖挑战”和“传硬币”两个游戏, 分别领悟简单设计、提早测试、快速反馈、减少批量, 提高交付速度的重要性. 把项目需求条目化, 定期排序, 确保有限的资源和时间用在最有价值的事情上. 从工具开始落地敏捷, 提升效率. 利用开源软件的优势, 站在巨人的肩膀上开发. 采用了以下工具, 如项目管理工具JIRA、知识管理工具Confluence、代码托管平台GitHub、代码缓存及管理仓库工具Nexus、持续继承工具Jenkins、代码静态审查工具SonarQube、自动化部署工具Ansible 针对人手不够, 而阻碍工具落地的情况, 采取以下措施: 通过工作坊和团队一起找出痛点, 列出所有改进点并进行优先级排序 每个团队每天划出一个固定时段, 半小时到1小时, 这段时间内, 所有团队成员放下手头的交付工作, 自行或组队摘取改进点进行实施, 并建立激励机制鼓励大家积极参与. 以团队共创形式开展工作坊: what 和团队一起找出痛点, 列出所有改进点并进行优先级排序 how 主题介绍. 主要是确立目标. 头脑风暴. 每个人先列出实现目标的障碍和对应想法, 然后分成几个小组, 每个组把组员的想法, 都进一步提炼成几个想法. 排列组合. 对每个组提炼出来的想法, 再进一步归类. 提炼中心词. 对每类想法, 提炼中心词. 模型图. 思考中心词之间的逻辑关系, 通过关系摆放形成图形, 解读图形, 制定行动方案. 通过工作坊, 发现以下问题: 1)业务请求跟踪性差 2)缺乏回归测试 3)手工部署 针对以上问题, 采取相应措施: 1)-1 JIRA记录所有的请求和需求, 建立可视板使进度可视化. 1)-2 每日站会围绕JIRA可视板进行,确认每天的优先级、进度、阻碍. 1)-3 通过Confluence建立项目文档和知识库. 使所有知识和信息透明化, 提升沟通和学习效率 2) 找出合适的自动化测试方案, 通过Jenkins每天自动执行全部自动化测试并发布测试结果, 结合SonarQube观测测试代码覆盖率是否处于上升趋势 3) 通过Ansible编写部署脚本, 实现部署自动化. 实施过程的阻碍: 遗留代码耦合度高, 可测试性低, 导致自动化回归测试落地缓慢. 上线流程烦琐, 倾向延迟修复版本的上线而造成更大的业务影响. 不管付出多少努力, 零缺陷和零风险都是不可实现的, 很多问题只有在生产环境才会出现. 做到真正的持续交付、频繁上线, 每次上线所涉及的变更范围缩到最小, 当问题出现的时候, 能更快地修复问题并把业务影响降到最低. 项目试点实践经验: 采用新交付方式, 规范并简化流程: 拥抱变化 适应任何需求变化以满足业务部门的最终需求. 拆分原始需求并快速交付其中最重要的部分获取反馈并及时修改 拆分 把大的需求拆分成最小可交付需求来缩短交付时间和实现持续交付 简化流程 最终用户与IT工程师直接沟通, 减少交接与签署, 不再依赖繁文缛节的文档. 业务部门可通过JIRA Service Desk直接提交需求, 规范交付文档, 使业务部门和IT部门对验收条件达成共识. PS: 以前老大也经常这么说，产品提的需求只是个解决方案，还需要跟业务沟通，把握真正的需求 透明可视化 需求与细节都记录在JIRA上. 通过看板可视化进度与阻碍. 定期汇报 改进服务 上线后业务人员可为每个交付评分和反馈意见 基于产品的持续改进: 建立CI/CD流水线, 加快暴露集成问题 实现基于主干开发, 避免上线代码非测试过的版本等问题 特性开关控制新功能 采用敏捷估算预测交付时间, 迭代进行过程中, 通过燃尽图持续观察团队的交付速率, 并及时调整预测. 从满足对方要求的定制化接口到通过API开放数据: 采用演进式的设计方法和微服务架构. 先搞清楚对家需要哪些数据(可根据对家系统所要求的接口文件规格文档), 然后为此设计Process API, 满足对家直接访问的需求. 在底层, 对数据按照领域进行归类, 设计相应的Domain API, 从Domain API获取元数据整合出Process API所需要的数据. 实施部分, 每个API都是一个独立的微服务应用, 基于Spring Boot开发. 借助Spring Cloud来搭建整个微服务框架. 通过Spring Cloud Contract框架实现契约测试. 从“预算驱动交付”到“价值驱动交付” 引入服务等级, 统一确定请求优先级来安排产能: 延迟成本，cost of delay，计算每个请求如果逾期的话造成的损失，将其折算成金钱，来量化所有请求的优先级 服务等级，class of service，对于不同的请求类型，赋予不同的服务等级，区别处理 加急类(Expedite), 常见于一些时效性特别强的需求, 或者对产品重大缺陷的修复. 这一类请求将被视为最高优先级, 可以无视最大在制品(WIP)的限制而直接进行作业. 然而这样的请求, 很容易对看板的正常工作造成冲击, 因此加急类的任务个数, 通常仅设置为1. 固定交付日期类(Fixed Delivery Date), 推荐安排一定的产能来处理一些固定交付日期的请求. 对于这一类请求, 需要交付团队在开发之前对请求的工作量进行估算, 并在开发过程中定期地确认进度. 一旦发现进度落后到有可能无法完成的地步, 则需要交付团队对请求重新进行评估. 如有必要, 这类请求可以升级为加急类. 标准类(Standard), 最普通的请求. 推荐大部分的产能都归类到此类请求. 交付团队无需对请求的工作量进行估算, 直接按照先进先出的顺序进行处理即可. 但对于超过两周工作量的请求, 建议先进行拆分. 无形类(Intangible), 主要针对一些用户价值有限的附加功能, 推荐安排此类任务上的产能应该低于标准类的产能. 采用关键链方法, 把约束理论运用到项目管理中, 解决依赖冲突, 突破项目管理的瓶颈 新项目由于资源冲突, 计划时间超出规定的交付时间. 同时考虑到原来的计划是有安全时间的, 于是调整计划, 把所有任务的时间减半, 而这些被扣除的安全时间放在最后一个任务后作为项目缓冲时间 对于IT部门, 致力于培养能做到端到端交付的T型人才 模糊原来诸如BA、开发工程师、测试工程师、运维工程师等的明确的职能分工, 尽可能做到负责一个用户故事或需求的端到端交付, 包括分析、开发、测试、运维等 相关概念敏捷方法论Scrum 方法选择: 有专属团队的纯开发项目，需要稳定的交付节奏的项目，适用Scrum。需要跨项目、跨团队合作的，一人分饰多角的，维护类型的项目，适用看板 相关概念 Product Owner（PO），用户/客户/业务代言人，即可以做出业务决策（需求和优先级）的人 Scrum Master，熟悉Scrum流程的人，指导和确保团队以Scrum的方式进行交付 Sprint，对迭代的说法。一个项目或产品的交付就是由一个又一个的Sprint构成的 User Story，用户故事。具有业务价值的交付单位，一个项目或产品由很多用户故事构成 Product Backlog，可理解为项目的代办列表，由用户故事构成 Sprint Backlog，一个Sprint的代办列表，确定Sprint里有哪些用户故事，框定Sprint的开发范围 过程 每个项目或产品的交付由若干个Sprint构成。Sprint的周期是固定的，以保持节奏。通常是2-4个星期，不建议超过4个星期 每个Sprint开始时，PO和IT团队一起开Sprint计划会议，PO对Product Backlog中的用户故事进行排序，选出最重要的用户故事 IT团队对这些用户故事进行估算。Sprint的周期和团队成员数量的确定，也确定了团队的大概交付能力 确定哪些用户故事会放到这个Sprint的Backlog里，作为Sprint的开发范围 围绕用户故事开发，每天一次站会，汇报昨天做了什么，今天会做什么，昨天遇到什么问题, 而且控制会议时长和参会人数以提高效率 Sprint结束的时候，开评审会议，展示交付，PO的反馈，包括需求变更都可定义成新的用户故事放到Product Backlog里重新排队 敏捷的所有改变都是为了快速反馈 短迭代开发，让PO更快、更早地看到成品，给予反馈 每日站会，每天都能看到进度和阻碍 回顾会议，每个迭代都反思改进点，形成持续改善的机制 极限编程 12个实践 确保开发可更早开始和迭代式的持续交付 计划游戏，planning game， 把整个项目拆分成从几天到几个星期的若干个迭代，把需求拆分成一个独立的用户故事，放在Backlog里——》每个迭代开始时，用户对用户故事进行排序——》通过估算确定哪些用户故事可在整个迭代里开发。且只对当前迭代进行计划，新需求产生的用户故事要放到后面的迭代中 小型发布，small release， 每个迭代后，所开发的用户故事都可发布或展示给用户，获取反馈，新的用户故事放到后面的迭代中 确保客户和交付团队都明白在做什么 现场客户，onsite customer， 用户应该和交付团队始终在一起，持续参与到项目中，阐明用户故事的具体需求和用户故事优先级，给交付团队及时的反馈 系统隐喻，system metaphor， 记录用户故事需求时，用交付团队和客户都能理解的语言编写 编码规范，code standards， 有一套整个团队都认可的规范 结对编程，pair Programming， 两个人结对在同一台计算机前来完成编程，一次性完成编程与评审, 共同讨论设计、测试、编程. 解决传统事后代码review, 需要重写单元测试及review参与度和质量的问题 测试驱动开发，test driven development， 在编程前就根据用户故事的需求写好测试（自动化测试），通过测试来验证编程代码是否满足需求 持续集成，continuous integration， 每天或每次有代码提交时就集成一次（编译、运行所有自动化测试、打包）, 尽早暴露问题并及时修复 重构，refactoring， 不改变功能和外部行为而优化代码的可读性、质量、性能，有了自动化测试和持续集成，可保证重构后出现测试失败，立即回滚代码 简单设计，simple design， 只为当前要做的需求进行最简单的设计, 因为越简单的东西, 越不容易出错, 越复杂的东西, 越容易出错. 而如果设计不能满足需要时, 在自动化测试和持续集成的保障下, 通过重构来解决. 代码集体所有权，collective code ownership， 在自动化测试和持续集成的保障下，任何人都可以对代码重构 每周只工作40个小时，40-hour week, 保障每天足够的时间恢复精力, 避免提前透支精力 5个核心价值 沟通，communication、简单，simplicity、反馈，feedback、勇气，courage、谦逊modesty 看板（另外一种敏捷、精益的方法） 原则 进度可视化 识别整个交付从左到右的各道工序哪里是瓶颈 根据约束理论，一切瓶颈以外的改善都是徒劳的. 约束理论Theory of Constraint，TOC，帮助企业识别出在实现目标的过程中存在着哪些制约因素，并进一步指出如何实施必要的改进措施 限制在制品（WIP，Work-in-progress） 一个请求，只有所有工序都完成并交付到客户那里，其价值才能得到体现 大量在制品堆积会导致优先级迷失和任务切换，任务切换又会导致效率低下，降低交付速度 只有下游有闲置产能才从上游拉入新的请求，避免在制品堆积 Scrum限制在制品的方式是, 通过Sprint计划会议限制每个Sprint放入的用户故事 看板则是在每道交付工序中限制并行任务数量, 随时都可以把新的请求放入Backlog中并排序, 只要有闲置产能时就把优先级高的请求拉入进程 观察和改善流动 与Scrum相通的地方 都基于敏捷与精益的原则，追求价值，消除浪费 都是基于拉动的计划系统 都限制在制品 都通过透明化来获取快速反馈 都聚焦于更早和更频繁地交付软件 都需要把大需求拆分成小故事 how 可利用JIRA，按需定义看板的范围、外观、限制在制品数量、泳道、卡片的外观等。每天对着JIRA看板来开每日例会，业务也可通过看板的情况来判断团队分配是否合理，及整个交付过程的瓶颈在哪 观察看板时，要关注的是有没有空闲的任务，而不是有没有空闲的人员 从右往左看, 先聚焦在制品, 尽快把在制品完成 看累积流图，一个面积图，强调用户故事或是需求数随时间而变化的程度，直观显示整体趋势走向。x时间，y需求数量, 不同颜色的面积区分如待处理、处理中、已完成状态的需求。 用户故事地图 why 真正的敏捷开发必须是基于用户故事的开发过程 如按报表来拆成若干个用户故事，选最常用的报表（对业务有价值的最小单位）先开发给业务测试，更快的获得反馈, 使大部分问题能更早地暴露, 为其他用户故事打下基础，通过早交付、早测试、早验收把产品的方向确定。 如果只是按功能点拆分，单个功能点的完成没有什么业务价值，无法测试 how 从左到右按时间顺序罗列用户行为（流程的每一步）——》在每个用户行为从上至下地罗列相应的细节（包括所需的开发点）。基于这张地图，还可对每个开发点的业务价值进行审视，找出最小可用产品（MVP，Minimal Viable Product）并制订发布计划. 制定发布计划时，遵循刚刚好good enough、更好better、最好best的演进原则 记录家里所有物品的APP，每购入新物品就记录 用户故事地图 回顾地图，梳理每个用户故事的优先级，设想如果我们要在一周内做出MVP，会做哪些用户故事 定义MVP的必要性: 开发一个功能所需要的时间与成本总是超出预期的 需求是需要验证的假设，通过MVP可以快速试验，通过最小成本验证需求假设是否成立 MVP是从整个业务角度来找出一个既能实现相同业务目标、IT成本最小的方法来快速启动新业务 如，要开一家提供网上订餐外送服务的餐厅，半个月内做出一个静态网站，展示菜式和订餐热线，生意就可在半个月之内运作起来。审视的是整个商业模式，不光是IT功能，更重要的是这样的外送服务模式是否可行和菜品是否受欢迎 用户故事拆分, 使故事最小化 3C原则 Card（地图） Conversation，确定发布计划后，要和PO围绕当前发布计划中的每一张Card聊具体需求 Confirmation，确定验收条件 敏捷落地比较图 DevOps 敏捷打通了业务、开发、测试之间的墙, 通过更紧密的沟通与交互实现更频繁的交付. 而开发与运维之间还有一堵墙, 运维也需要稳定的部署、监控支持持续交付. DevOps就实现开发与运维一体化和端到端的持续交付，融合了敏捷与精益的精神, 涉及自动化、精益思想、量度和分享. 精益是从丰田生产系统移植到软件开发的方法, 看板方法就是其中一种精益方法. 交付文档模版: 需求描述 作为（谁），我想要（做什么），为了（为什么）。 行为驱动开发: 业务人员确定对系统的期望行为，采用业务部门和IT部门双方都能看懂的统一语言Gherkin的given when then的语言格式, 编写验收实例, 再通过自动化测试框架cucumber执行实例，实现验收测试自动化，并纳入持续集成 cucumber，一个用普通语言描述测试用例的、支持行为驱动开发BDD的自动化工具，由Ruby编写，支持Java、.NET等多种开发语言。 确认理解 复述对需求的理解 问为什么 在什么场景下需要这个需求，包括谁用、什么时候用和使用条件、要解决什么问题、使用频次、怎么发生等（挖掘真实用意，因为有些需求是解决方案） 验收条件 “完成定义”, Definition of Done 实例化需求, 验收测试用例的具体例子. 避免误读, 让抽象的需求变得具体和可测试. 以终为始，一开始明确要做成什么样，指导行动并确保结果正确。包括happy path和exceptional scenario 详细设计与实现 集成测试结果 用户验收测试 上线备忘 上线所需要的额外步骤 敏捷估算 敏捷采用的估算单位是故事点, 一个和复杂度或规模有关的相对数, 而用户故事的复杂度或规模, 是一个相对时间更稳定的常量, 因为时间是不可控因素, 同样的需求不同人做的耗时差异性很大. 扑克牌游戏方法 团队每个成员都有一副扑克牌, 每副扑克牌包含一个不同的数字, 如斐波那契数列, 然后对应故事点分别为1, 2, 4, 6, 10等. 当大家都消化完一个用户时, 同时通过出牌的方式来展示每个人的估算结果. 给出最高和最低估算的两人要解释和辩论. 最后团队得出一个大家都认同的估算值. 该方法的原理就是利用人群中涌出的群体智慧远远超过个人智慧. 估算时间 首先测试交付速度. 观察团队在头一两个迭代中可以实际交付多少个故事点来预测团队的交付速率, 从而计算完成所有故事点需要多少个迭代. 而在Scrum, 迭代的周期是固定的, 知道有多少个迭代就能知道需要多长时间 在迭代进行过程中, 通过燃尽图来持续观察团队的交付速率是在提升还是下降, 随时作出调整 关键链 关键路径是项目活动及其逻辑关系图中最长的路径, 通常决定项目工期 而关键链是决定项目长度的全部关键因素的关键路径和其他一些需要关键资源的任务 把关键链上所有任务被扣除的安全时间放在最后要给任务后作为项目缓冲，保护项目不受关键链任务延迟的影响。所有非关键路径上的任务被扣减的安全时间也集中在一起作为接入关键链的接驳缓冲，保护关键链不受这些任务延迟的影响 如果按非关键链的做法, 为所有的任务都加入安全时间, 会被学生症侯群、多任务和延迟的累计浪费掉所有的安全时间, 从而导致项目延迟 学生症候群指通常人们会先极力争取安全时间, 得到安全时间后, 就不着急, 真正开始往往在最后一刻, 造成安全时间被浪费. 所以在任务阶段剥夺安全时间可以迫使相应的资源在任务开始的时候就全力以赴地执行任务 估算通常被视作承诺, 考虑到今后的估算被压榨, 人们通常不会呈报提前完工, 这部分的延迟会转嫁到下一个任务, 而最终导致项目延迟. 而关键链方法, 任何任务提前完成都增加到缓冲区 关键链区别于关键路径主要是, 关键链考虑了资源冲突. 把安全时间从每个任务中转移出来的前提是, 每个任务所需要的资源都能聚焦在当前任务上 约束理论五步法 定义系统限制（瓶颈） 决定如何充分利用限制 让非限制资源充分配合 打破系统限制 若限制已打破，回到步骤一 其他相关思维: 真正的持续交付需要从左端的业务需求到右端的上线全流程配合 计划不是为了执行, 而是提前做好各种情况的预案, 集结资源, 以应对将来可能的各种变化 敏捷开发提倡信任、自治及通过技术手段如自动化测试来取代繁文缛节的文档.变革需要整个公司文化和价值观上的改变与配合以及人力、工具的投入, 只有管理层的支持才能使变革遍地开花. 个人感悟 上一篇《凤凰项目-三步工作法笔记》中, 提到多读书真的很重要, 因为虽然知识不能改变命运, 但是能改变思维. 后来我想了下, 应该是”意识到必须做出改变“更重要. 那样看了书之后, 不是只有“哦, 我知道了”, 而是会想办法把书里面的内容吸收用起来. 比如说, 把迭代思维融入到日常生活中, 其实是一种解决拖延症的好办法, 把要完成的事情拆分到足够小, 小到不用犹豫就能做的, 同时把这些任务可视化, 持续监控并调整自己的行为, 直到完成. 而“限制在制品”的应用, 就是把任务拆分到足够小之后, 排好优先级, 一件一件的完成, 减少不必要的任务切换, 专注于尽快消除未完成的任务. ps: 尝试了一段时间后, 还是有些问题, 最重要的原因, 应该是缺少反馈, 多去接受外界的反馈才是真正的走出舒适圈…","link":"","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://yummyisminer.xyz/blog/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"敏捷","slug":"敏捷","permalink":"https://yummyisminer.xyz/blog/tags/%E6%95%8F%E6%8D%B7/"},{"name":"DevOps","slug":"DevOps","permalink":"https://yummyisminer.xyz/blog/tags/DevOps/"}]},{"title":"凤凰项目-三步工作法笔记","date":"2020-04-14T04:31:11.000Z","path":"/posts/d698d359/","text":"前言:去年想了解DevOps的相关概念, 看了《凤凰项目》这本热荐的入门书. 虽然看起来是一本技术相关的书, 其实以第一人称的视角来讲述, 一个IT运维经理临危受命, 推动项目转型的波折和故事, 特别生动有趣, 每个人物也个性鲜明, 搞得我明明在严肃认真的学习, 却常常像看了不正经的书似的哈哈大笑… 书中还穿插各种吐槽, 有同感的是, 我也在公司年会节目上改编过一首歌词吐槽bug什么的, 不过好在大家都挺包容的… 😄 ✨ 不过, 只看一遍过过瘾是不行的, 所以整理了下读书笔记. 下文中就包括《凤凰项目》的故事脉络、有趣段落摘抄、相关概念、个人感悟. 故事脉络:主角比尔, 一家制造和零售企业的IT运维经理, 面临着被竞争对手不断超越的困境, 接任IT运维部的副总裁, 管理一个叫凤凰的电商系统项目, 以此招揽客户并拯救公司的经济危机. 可视化管理流程刚上任就发生工资核算故障, 起因是开发部为了修补一个审计发现, 没遵照规定的流程和测试, 直接部署了个有bug的标记化应用. 暴露的问题: 流程繁琐、响应慢, 所以申请测试环境的预算一直没审批, 而无法测试; 各部门沟通、协调不到位; 业务市场部不断压缩IT部交付部署时间、迫切想先人一步抢夺市场; 运维部不能及时交付, 开发部申请的设备、环境; 关于项目完成的定义不统一, 开发部没有考虑运维部署的时间, 总是匆忙上线; 开发部没有提供清晰的部署文档, 使运维部无法顺利部署, 无法进行压力测试, 没有全面监控和备份; 运维的关键工程师总是要处理各种故障, 没办法参与开发部的计划会议; 没人清楚公司整体业务架构, 都在瞎忙; 为了解决以上问题, 采取以下措施: 列出工作任务清单, 了解工作需求、优先级、工作进度、可用资源(如人员职责, 所需时间), 预估工作量, 并合理调配资源; 识别变更冲突以及可用资源矛盾的风险, 做出相应调整; 设定变更流程, 稳定工作环境, 可视化管理IT运维部里的半成品; 在白板上, 列出所有的变更、相关人员. 所有人一起讨论变更的类型，然后对变更进行筛选和安排; 把一部分变更审核委派给代理人, 重点关注最有风险的变更; 预先定义好高风险变更目录, 列出十大最脆弱的服务、应用程序和基础架构列表, 对相关变更申请标上记号, 并详细审查; 围绕这些变更建立一些标准流程(如跟业务部门确认实施变更的时机), 相关人员关注变更、随时待命; 对于低风险变更(如增加Java应用程序服务器线程池容量), 仍需要提交, 但可以直接安排操作日程; 对于复杂的中等变更, 变更提交者获得可能受到影响的人员许可后, 再审核并安排操作日程; 规范流程, 保护约束点在一次排查故障问题会议上, 各部门又开始推脱责任. 而由于没有相关解决问题的知识库, 很多问题只有高级工程师布伦特能解决, 布伦特成了项目的一个约束点, 虽然也解决了故障, 但是比尔认为这次故障可能是布伦特的某次不规范操作导致. 于是, 采取以下措施: 记录所有的变更, 不准再出现未经授权或未公开的变更; 每两周组织一次排查故障的实战演练, 让每个人都养成运用合理的方式来解决问题的习惯; 如召开应急处置会议之前, 就要把相关时间线搞清楚; 减少需要布伦特的工作中心数量, 把布伦特的工作标准化，让其他人能够执行; 建立一个3级工程师的人力资源库, 由他们处理流转过来的工作; 记录整理故障解决方案到知识库里, 生成能让一些工作中心自动化运行的文档; 每周逐项检查工作, 不能让布伦特就同一个问题出手两次, 否则3级工程师和布伦特都要受罚; 提供相关福利, 鼓励布伦特和工程师遵守新的流程; 保护约束点, 让布伦特只做最重要的凤凰项目的工作; 任何占用布伦特时间的人都要解释说明, 否则上报; 过滤涌向布伦特的变更任务, 并在变更卡片上表示出来; 收集直接找布伦特的名单, 给他们的上司打电话, 让上层知道有人在干扰凤凰项目; 问题频出, IT不受上层信任因为开发没告诉运维需要打开一个防火墙端口, 而前端程序与数据库服务器通信失败, 代码无法在测试环境中正常运行, 延误了凤凰项目的上线. 以及一些接口延时, 性能相关的bug, 导致所有店内POS系统都会宕机. 暴露的问题: 部署运行测试的时间太长, 跟不上开发的节奏; 缺乏版本控制, 开发提供的是不完善的版本, 导致配置测试环境时, 浪费了不必要的时间; 采取措施: 代码试运行每天只能进行两次, 并限制所有影响性能的代码变更; 开发人员, 提交的代码必须标注对应某个性能问题的缺陷编号; 而这些问题使上层不信任IT部了, 要将IT部外包. 比尔和开发部老大克里斯因此进行了一次深入交流, 发现大家的压力一样大, 也为公司付出了不少. 克里斯说, 他们总要不断追赶新技术、新的项目管理方法, 一直疲于应付各种故障修复，无暇顾及功能开发, 业务部门还总是不跟IT部门商量可行性, 就直接下达任务. 上下一心, 重建团队信任 客户发票系统发生故障, 比尔团队通过一系列不间断的事后调查，搞清楚了故障的来龙去脉，采取了预防措施。同时开展了一系列全员参与的模拟事故呼叫，排演新的处理步骤, 一切都在有序的进行着. 但CEO史蒂夫认为IT部没有‘紧迫感’，要求所有相不相关的工程师都要‘手不离键盘，不能有闲人’, 比尔因此辞职了. 与埃瑞克沟通并反思后, 史蒂夫明白了IT对公司日常运作起到关键作用, 必须重视IT, 所以召开IT领导外场会议, 重建团队信任. 他先自曝, 从刚进部队时不被人看好, 一路奋斗到CEO的经历。然后几个IT领导也各自分享自己的故事, 到比尔的时候, 比尔说因为有个不称职的父亲, 他离家出走, 加入海军陆战队后, 明白了一个人可以通过做正确的事, 而获得奖励, 所以他关心孩子, 要当个好父亲, 也让他形成了现在这种严遵规范的行事风格. 然后大家也交流了一些现有问题, 并达成和解: 对‘已完成项目’的定义不统一. 开发团队没把运维部的工作列入考虑范畴; 运维部不能及时部署交付; 冻结项目, 根除计划外的工作除了变更板上的任务外, 常常还有些计划外的救火工作, 而且随着时间推移, 还会不断增加, 约束点未被充分利用, 没向业务部门交付全部的可用资源. 董事会新成员埃瑞克启发, 类比工厂的库存堆积, 如果停止向车间发布工作和原材料, 工作以成品的形式离开工厂, 半成品数量下降, 交期性能会提升。在IT部, 也要考虑部门的实际工作能力和负荷量, 保证足够时间和精力开展制定计划，考虑清楚是否可以接受新的工作, 否则, 项目的可用工作周期变短，出现更多走捷径的技术债务, 更多脆弱的应用程序, 需要以计划外工作的形式来偿还那些技术债务的利息。 采取的措施: 清楚约束点是布伦特, 采取措施保护布伦特不受计划外工作的影响, 确保约束点从不浪费时间, 建立起一个可信赖的系统用以管理通向约束点的工作流, 根据布伦特来设定工作节奏; 除了功能开发，还要关注稳定性、安全性、可扩展性、可维护性、可操作性、持续性以及其他诸如此类的性能; 确认最主要的技术债务，开发部会对其进行处理，以减少问题应用程序所产生的计划外工作量; 确认凤凰项目是优先级最高的事, 接下来两周, 冻结所有凤凰外的部署工作, 继续开展其他正在进行的项目，减少IT半成品数量; 项目冻结行动让IT得以把力量聚焦到凤凰上，七天里完成的工作比以往整个月完成的工作还要多。但项目解冻后, 面临两个问题: 项目冻结解除后，发布哪些项目是安全的, 如何区分工作的轻重缓急. 在完成工作之前，要先分类列出工作所需的全部前提条件, 再加上工作订单和现有资源，理解生产能力和需求是什么, 进而可以判断是否可以接受一个新工作并对其作出实际安排。而布伦特是一个约束点, 支持了多个工作中心。假如25%的工作中心都只能由布伦特来操作，而布伦特在同一时间只能呆在一个工作中心, 工作将无法按时完成. 所以先了解工作如何流经某些工作中心, 根据对布伦特的依赖程度来决定能够安全重新启动的项目。 启动监控项目是否安全。 期间也发生了一次服务中断, 原因是一个网络服务供应商意外对系统作了一个变更. 而一个监控关键系统是否出现未经批准的变更的项目, 可以防止服务中断, 有助于进一步优化工作流转至约束点布伦特的流程, 让工作流服从于约束点, 尽量少依赖布伦特。 围绕约束点改进, 减少等待 ‘第二工作法’的一个关键部分是让等待时间可视化，使没有完成的部件，或者需要返工的瓶颈点一目了然。要把注意力从工作中心转到工作中心之间的那些空间上, 管理好工作交接。如下图, 一个给定资源的等待时间，是那个资源忙碌时间的百分比除以空闲时间的百分比。如果一个资源使用了50%，等待时间就是50/50。如果这个资源使用了90%，那么等待时间就是90/10。当一个资源使用了99%，那么等待时间就是该资源使用50%时的99倍。 在代码投产之前，还未产生任何价值，因为那只是困在系统里的半成品。要着眼于整个工作流，确认约束点的位置，并尽其所能地运用各种技术和流程知识来确保工作得到有效执行。 所以, 帕蒂参考工厂管理工作流中白板管理技术和迭代改进的方法, 找出最经常出现的任务，建立起工作中心和工作路径, 写下操作步骤以及执行这些步骤的人员，测定每个操作所需的时间, 找出可优化的步骤, 降低重复次数。把这样的日程安排表换成看板图，索引卡片的每一行写的是分配的任务, 每一行都划分成三列，标注着“待办”、“在办”、“已办”。而用不同的颜色区分不同种类的卡片, 确保大家都在做最重要的工作, 一眼就能确认工作中紫色和绿色卡片是否平衡。 关键资源所从事的任何活动都必须通过看板, 让需求和半成品可视化，限定半成品, 制止工作缺陷交接至下游工作中心, 加快工作完成的速度。规范布伦特接手工作的方式，把他的工作标准化。从上下游两个方面弄清楚布伦特的工作来源, 阻挡那些想打布伦特主意的人。能预测工作的交货时间, 能让用户满意度上升, 让大家专注工作. 管理工作流，运用约束点来控制节奏. 像工业生产控制部那样, 安排并监督所有的生产过程，确认每一个需要的工作中心都有足够的生产能力和必要的投入, 确保能够符合客户的需求。与业务项目关联的IT项目, 也根据业务价值, 安排工作. 根据全体项目主管的排序，确定了项目解冻时要发布的最重要的五大业务项目。对于内部项目, 则根据项目能否提高在约束点(布伦特)上的工作能力，只开展能减少他的工作量，或者可以让其他人接手的项目。无限期暂停对那些非脆弱系统进行基础架构更新的项目。 凤凰项目的一个任务又延期了, 因为布伦特的‘任务’是涉及多个人员的多个任务，开发部和IT运维部两个部门之间的工作交接，也涉及多个人员之间多次交接的多个步骤, 而每一次工作交接都有损耗的时间。因此, 为需要跨部门交接的‘任务’都设置一条看板追踪路径, 把这些经常性工作记录在案，将其标准化，并且熟练掌握, 提高流量，最终就能达到产品配置的一致性。同时, 新增兼有项目经理和稽查员的职能的角色, 他们要提供每一分钟的控制。让所有已完成的工作都快速有效地交接到下一个工作中心。必要时，这个人要在工作中心等待，保证关键工作完成并快速运往下一个工作中心, 减少悬而未定的项目数量，让工作流转的通路保持通畅。 从企业目标出发, 专注要事 公司最大的风险是停业破产, 目标是提高整个系统的生产能力, 而之前一直死守的‘安全性’项目会降低凤凰的项目吞吐量, 凤凰项目吞吐量是整个公司的约束点. 所以安全部的约翰, 先找到财务部的经理迪克, 了解他在公司的确切职能, 远期目标、近期目标和评估指标. 迪克认为最重要的公司远期目标, 应该从整个系统出发, 对公司系统具备根本性的认识, 始终确保在一个正确的市场里, 作出正确的产品策略, 让企业达成目标, 那样财务目标才能发挥作用. 我们有竞争力吗？了解客户的需求和期望：我们知道要创建什么吗？产品系列：我们有正确的产品吗？研发效能：我们能有效地创建产品吗？上架时间：我们能尽快把产品推向市场并占有一席之地吗？销售机会渠道：我们的产品能带来感兴趣的潜在客户吗？我们的效率高吗？按时交货：我们遵守了对客户的承诺吗？客户保留：我们是在获得客户，还是在流失客户？销售预测准确率：我们可以把销售预测准确率纳入销售计划流程吗？ 比尔他们才意识到应该把迪克的重要评估指标作为IT任务的前提条件, 真正理解IT所参与的业务系统。于是决定, 去和业务流程负责人谈谈关于迪克说的公司的目标任务，弄清楚他们的确切职责是什么，哪些业务流程是支持其目标的. 找出对公司实现长期目标危害最大的几项内容, 弄清楚IT部门所负责帮助支撑及维护的公司业务. 帕蒂和比尔将对业务流程负责人进行访谈，主题是“理解客户的需求与期望”、“产品系列”、“上市时间”以及“销售渠道”. 销售部总裁罗恩认为, 差劲的‘了解客户的需求和期望’影响了‘销售预测准确率’，需要知道门店里有哪些产品缺货，进而提升销售额. 关于销售渠道流程及其困难的问题: 销售经理们很难从客户关系管理系统（CRM）中拿到需要的报告. 糟糕的一天是什么样: 负责管理的物料需求计划(MRP)系统和电话系统都崩溃, 服务中断, 客户取消订单, 无法完成业绩指标. 比尔接着解释, 电话系统故障是因为供应商未经授权就对电话交换机更换, 等预算批下来, 就能通过监控来强制实行控制策略, 杜绝问题. 业务发起人玛姬说, 她对‘了解客户的需求和期望’的衡量标准是，客户是否会向朋友推荐我们, 但是订单输入系统和库存管理系统的数据总是错的, 导致不能通过销售数据知道客户想要什么. 假如能挥舞魔杖, 会怎么做: 她希望从门店和在线渠道, 有方便易用的功能, 得到准确及时的订单信息。运用那些数据来设计市场推广活动，不断推出“A或B”产品选择测试，以发现客户认可的报价, 并在全部客户中复制推广。就能为罗恩创建一个巨大的、可预测的销售漏斗。运用那些信息来推进生产计划，管理供求曲线。让正确的产品出现在正确的货架上，并一直备好库存。平均每客户销售额将会一路冲高，平均订单金额也会上升, 最终会提高市场份额，并再次打败竞争对手。 对于上市时间, 玛姬认为要控制在6个月内, 要不断降低周期时间, 不断整合来自市场的反馈, 增强回收成本的能力，最好从消费者那里直接回收成本. 建立起价值链, 包括IT方面的所需的价值链，把迪克的目标任务与IT对这些目标任务的影响关联起来，收集以前IT问题如何影响那些目标的具体案例, 对业务绩效指标产生影响的IT风险，就要着手制定更好的业务决策。弄清楚达成迪克期望结果所需要的业务能力和流程；那些业务流程所依赖的IT系统；IT系统或数据可能会发生的故障；防范那些故障发生的应对措施，或者至少能够侦测并作出回应的措施。 通过与业务负责人的访谈, 理解了哪些是重要的工作, 让业务部门相信, IT的应对措施有助于他们达成目标, 和他们一起开展把IT融入其绩效指标的工作采取措施: 对于“客户的需求和期望”, 目标是数据的完整性, 凤凰修复了很多这方面的问题, 还需要控制由上游产生的问题; 预测评估指标包括遵守变更管理流程、监督审核生产变更、完成定期维护，以及排除所有已知单点故障; 创建一份完整的清单，把所有支持罗恩的应用程序和基础架构都列出来。只要其中有任何脆弱的应用程序或系统，就要把它们添加到替换清单里; 对于“市场营销的需求和期望”，评估指标包括凤凰支持每周报告并且最终支持每日报告的能力，市场营销部生成的有效SKU比例等; 把发布变小变短，减少半成品和功能, 更快地回笼资金，达到内部最低预期资本回收率; 约翰研究业务部门的安全控制环境, 了解到一个拥有技术背景财务人员, 她分析一个财务方面的重要会计科目中的主要业务流程的端到端信息流, 发现, 在一个人工对账步骤中检测到重大错误，在这个步骤中，来自一个源头的账户余额和账户值要和来自其他源头的逐一比对，一般是每周一次。如此一来, 检测重大错误所依靠的控制手段是人工对账步骤，并非上游的IT系统, 所以审计师撤回他们的IT发现. 针对调研, 知道了审计安全的关键落脚点是, 确保财务报告的可靠性，符合法律法规，以及运营的效率和效果, 并提出建议: 大幅度缩减安全合规项目的范围; 弄清楚生产薄弱点一开始是如何产生的，调整部署流程，杜绝此类情况再次发生; 在变更管理流程中，标记出所有列入合规审计范围的系统, 避免可能危及审计工作的变更, 创建持续记录文档; 通过清除所有存储或处理持卡人数据的东西，来缩减PCI合规项目规模; 用节省下来的时间，偿还凤凰的所有关于战略风险、运营风险、严重的安全与合规风险的技术债务, 关乎关键评估指标; 形成反复实践和勇于尝试的团队文化 对需要团队合作的事情，训练成习惯，不断重复可建立起信任感和透明度。定期回顾小结，对工作开展情况以及需要改进的方面进行自我评估, 同时邀请开发部的人参加服务中断根本原因分析会. 类比跨国货运公司，要达成客户满意度和按时交货的目标。为降低更换机油会导致车辆故障, 而影响按时交货的风险，就要为车辆运营建立一个每行驶五千英里就要更换一次机油的协议, 还有已经按要求更换机油的车辆百分比, 因为如果只有50%的车辆遵守了必需的保养策略，卡车和包裹就可能会抛锚在路边，那么按时交货KPI就会大幅下跌。同样, 为了达到公司的按时交货的关键性绩效指标（KPI），也要建立一个新的前瞻性KPI，预防性供应商补丁程序以及变更管理政策就好比是预防性机油更换以及车辆保养策略。‘第三工作法’就是要让我们不断给系统施加压力，适当提高预防性工作, 从而不断强化习惯并加以改进, 形成不断改进的文化, 加强系统的健壮性. 所以, 安全部开发了一些工具, 在日常工作中, 对测试和生产环境持续不断的攻击和压力测试. 虽然由于布伦特又一次没按流程, 部署了萨拉的一个供应商项目, 导致凤凰项目第二次部署遇到困难, 但最终还是完成了部署, 帕蒂发出部署是“成功”的通知, 并提醒需要提防的已知错误，提供一个可以获得凤凰最新状态的内部网页，以及如何报告新问题的指南, 全体人员随时待命，准备对业务提供支持. 这次部署失败证明, 批量规模还是太大了。要在IT部门创建一个单一向前的工作流, 让生产能力最大化，同时让变化幅度最小化。一旦看到工作向后移动，也许是由于不合格品、缺少规范，或者返工导致, 都得开展修复工作. 让最小可行产品(MVP)加速接受市场的考验 凤凰归根结底就是为了帮助客户快速、大批量地买走东西, 最近的两次发布也为此打下了基础, 但凤凰项目延误了太多真正提升销售的功能, 这个季度的盈利是不能指望凤凰了, 所以决定从凤凰主团队里分出一小队人，组建一支叫独角兽的特别行动队，聚焦于生成良好的客户推荐, 并让市场营销部门能够开展促销活动，把库存里现有的盈利产品卖掉, 尽快达到收入目标, 然后把探索出来的成功实践复制到凤凰中. 建立反馈回路, 持续交付 丰田公司有一个引擎盖冲压工序，最初转换时间约为三天, 仔细观察了换模所需的全部步骤后，提出了一系列预备和改进措施，把换模时间降至十分钟以内。相应的, 根据第二工作法，建立一条反馈环路，一直往回通向产品定义、设计及开发的最初环节, 延伸到产品生产流程的更早阶段, 在初始阶段就筹划产品的质量。开发部和运维部, QA和业务部门一起协同工作, 持续不断地降低批量规模, 对创建环境所需的每一样东西都进行版本控制, 从代码签入到投产的整个价值流, 创建‘部署管道’，在其中自动创建测试和生产环境，把基础架构当作代码一样对待, 构建一步到位的生产环境和部署流程, 缩短准备时间并排除故障, 更快的获取反馈, 才能跟上客户需求和开发部的各种工作节奏. 业务敏捷度重点是捕捉和适应市场变化并为此承担更大风险的能力, 要持续不断的尝试，越快把那些功能推向市场接受考验，也能更快地为公司收回成本。要达到一天十个部署的目标, 那部署可包括故障修复, 让市场营销部修改他们自己的内容或业务规则，或者启用更快速的试验和A/B对比测试. 为了找到可自动化的步骤, 分析从‘代码提交’开始，到部署成功的所有步骤, 和之前上线期间存在问题的步骤, 得出返工和准备时间过长问题的来源有两个： 环境: 在部署流程的每个阶段，部署环境总是没有就绪，即使已经准备就绪了，也需要大量返工才能让它们彼此同步 部署: 代码打包流程。尽管开发团队尽可能地记录代码和配置，但总是在IT运维部进行版本控制，然后生成部署包部署之后，代码无法在环境中运行, 才发现有遗漏东西。 采取措施: 收集从错误中吸取的各种教训, 编一本关于部署运行的书 设置一个通用构建过程，每个人都使用自己的工具来创建自己的环境，开发人员能在一个与生产环境相似的环境下编写代码 运维直接拿到准备部署的打包好的代码, 一旦代码被标记为‘准备测试’，就生成并提交代码包，触发一个QA环境的自动部署, 及后续生产环境的自动部署。 清除异党 市场部莎拉急于讨好上层, 又因为以前IT经常不能完成并交付她所需要的东西, 找供应商开发第三方服务, 这些看起来是战略性, 但实际不遵守关于数据隐私的法律法规，订单输入和库存管理系统出现更多的数据完整性问题, 还得向供应商开放产品数据库，向他们解释这些数据库是如何构建的，开展众多防火墙变更，等大量额外的工作, 阻碍了聚焦凤凰项目, 这些都是对公司不利的。 在独角兽项目的关键时刻, 迪克和财务团队要调走布伦特, 让他加入制定拆分公司方案的特别工作组。但只要完成季度指标, 保住凤凰项目, 就不需要拆分公司了. 了解客户的需求和期望，拥有正确的产品系列，保留客户，以及最终提高营业收入和市场份额，才是最重要的, 所以比尔把布伦特截回来, 在史蒂夫的帮助和众人的努力下, 独角兽项目上线后促销活动的客户转化率很高, 通过了市场的考验. 理解技术能够做什么、不能做什么，是公司里每个部门必须具备的一种核心竞争力。最后, 不能融入公司新文化的莎拉离职了. ————————–—以上为暂时梳理的故事脉络, 笔记还会多次迭代————————————- 有趣段落摘抄: 俗话说得好, 如果你的同事主动告诉你他们要离职, 那多半是自愿的.但如果是其他人告诉你的, 那他们一定是被迫的. 所以说, 我的上司和上司的上司刚刚被炒了. “比尔, 我知道你没有申请这个职位, 但公司已经命悬一线. 我需要你来帮助我拯救这家伟大的公司. 我能指望你吗?”啊, 我的天哪! 还没来得及礼貌地谢绝, 我突然听到自己说:“ 可以, 你可以指望我.” 迪克打断了她: “这是IT部的比尔.他说他是被派来收拾这个这个烂摊子的, 或者准备在收拾的过程中壮烈牺牲, 我是这么理解的.” “他摇摇头继续说：“要说服业务部门去做正确的事情越来越困难。他们就像走进糖果店的小孩子。他们在飞机杂志上读到，可以在云端管理整个供应链，每年只要499美元，然后这突然就成了公司的主要行动。当我们告诉他们，事实上没那么简单，并演示做好这个要花什么样的代价时，他们就不见了。他们去哪儿了？去和维尼表兄或者其他推销外包服务的家伙谈了，那些人许诺，能用十分之一的时间和价格做成这件事。” “我脑海里立刻浮现出这样的景象，约翰问了一些愚蠢的问题，或者说了一些愚蠢的话，彻底激怒了迪克，迪克当场解雇了他，为绝后患，就把我也解雇了。然而，我发现自己说的是：“好的，我会去的。” “他剃了头，看上去像瘦了十五磅。他穿着一件我只能描述为“欧洲式样”的衬衫和一件马甲。和他平常穿的略为宽松的衬衫不同，他身上那件粉色衬衫非常修身。再加上那件马甲，他看起来像是个……时尚模特？伦敦夜店男？拉斯维加斯赌场发牌员？” 相关概念:精益理论 包括: 1)降低批量规模; 2)减少半成品; 3)缩短并增强反馈回路 DevOps what 也就是开发运维, 这个词最初是在2008年由帕特克里.德布瓦和安德鲁.谢弗提出, 脱胎于马克.伯吉斯博士发起的“基础设施即代码”的实践及有杰兹.亨伯尔和戴维.法利发起的持续集成和持续部署. 应用了精益理论, 来提高流经生产管理、开发、测试、IT运维及信息安全等部门的工作流的速度. why 能使产品功能更快地进入市场, 创造价值. 在玩偶实验室2012年的“开发运维报告说明”中, 用基准问题测试4039家IT企业, 发现运用开发运维的高绩效公司比同行: 代码部署频率快30倍; 代码部署交付期快8000倍; 变更成功率高2倍; MTTR(Mean Time To Repair, 平均修复时间)快12倍. how 三步工作法 持续交付就是三步工作法中到一种体现, 它强调小到批次规模(如每天检查主干), 在发生问题时停止生产(如一旦构建、测试或部署失败, 就不再允许开展新到工作; 将系统工作到完整性置于工作本身之上), 并必须频繁进行验证性测试, 以避免生产中到失误, 或至少能检测并修复故障. 三步工作法 what 旨在阐明指导开发运维的流程与实践的价值观与理念. 第一工作法 what 关于从开发到IT运维再到客户的整个自左向右的工作流, 那是业务部门与客户之间的衔接. why 为了使流量最大化, 让批量规模和工作间隔尽量小, 不让缺陷流向下游工作中心, 并不断为整体目标(与之相对的局部目标就是开发功能完成率、测试发现/修复比率或运维有效性指标等)进行优化. how 必要做法包括: 持续构建、集成以及部署, 按需创建环境, 严控半成品, 以及构建起能顺利变更的安全系统和组织. 其中严控半成品就可以建立看板图, 列出: 待办、在办、已办 根据瓶颈资源所能完成的工作速度来安排工作, 确保绝大多数受约束的人力资源都只能投放在整个系统的目标所服务的工作上, 而不只是为了一个部门的目标服务 确保形成一条迅速、可预测、持续不断的计划内工作流, 从而向业务部门交付工作价值, 同时尽可能降低计划外工作的影响和破坏, 提供稳定的、可预期的、安全的IT服务. 第二工作法 what 关于价值流各阶段中, 自右向左的快速持续反馈流, 缩短及放大反馈回路 why 放大各阶段的效益以确保防止问题再次发生, 或更快地发现和修复问题, 从源头上保证质量, 避免返工. how 在部署管道中的构建和测试时, “停止生产线”; 日复一日地持续改进日常工作; 创建快速的自动化测试套装软件, 确保代码总是处于可部署状态; 在开发和IT运维之间建立共同的目标和共同解决问题的机制; 建立普遍的产品遥测技术; 让每个人都能知道, 代码和环境是否在按照设定的运行, 以及是否达到了客户的目标. 第三工作法 what 关于创造公司文化, 该文化可带动两种风气的形成: 不断尝试, 这需要承担风险并从成功和失败中吸取经验教训; 理解重复和练习是熟练掌握的前提. why 尝试和承担风险让我们能够不懈地改进工作系统; 不断重复的日常操练赋予我们的技能和经验, 一旦出了问题, 就可以撤回至安全区域并恢复正常运作. how 营造一种勇于创新、敢于冒险(相对于畏惧或盲目服从命令), 及高度信任(相对于低信任度和命令控制)的文化, 把至少20%开发和IT运维周期划拨给非功能性需求, 并不断鼓励进行改进 IT从事的四种工作类型 业务项目 IT内部项目 包括业务项目衍生出的基础架构或IT运维项目, 及内部生成的改进项目(如创建新环境和部署自动化) 变更 经常由业务项目和IT内部项目的工作引起, 往往在保修系统中被跟踪(如IT运维补救、JIRA或用于开发的敏捷计划工具) 计划外工作或救火工作 包括操作事故和操作问题, 通常由上述类型的工作导致, 往往以牺牲其他计划内工作为代价 约束理论5个方法步骤 识别约束点; 利用约束点; 确保不让约束点浪费任何时间。永远不要让约束点迁就别的资源而干等着，而是应该专注于IT运维部对当前所需完成工作中优先级最高的那一项。 让所有其他活动都从属于约束; 根据约束点的工作效率来控制其他工作的速度。在约束理论中，一般是由名为‘限制驱导式排程法’（Drum-Buffer-Rope）的工具来实施的。《目标》中的主角亚历克斯，发现队伍里最慢的童子军赫比实际上决定了整支队伍的行军速度，后来亚历克斯把赫比调到队伍前头，防止孩子们超前太远. 把约束点提升到新到水平; 寻找下一个约束点; 个人感悟: 也许大家都想把工作做好, 也为此付诸行动, 但是有没有在做正确的事就是另外一回事了. 这就需要切入顶层的上下文中考虑, 因为公司的存在就是要产生商业价值, 大家的工作就是要为业务服务. 而工作的完成, 也是多方合作的结果, 任何一个职位都很重要, 而且协调沟通还会影响整体的效率. 问题的存在不可怕, 当问题发生时, 要做的是找出应对的措施, 积极改进, 而不是推卸责任, 否则最终受累的也是自己. 而理论再完美, 最终还是需要不断尝试, 找到适合自己的解决方案, 只有实践了才知道有哪些问题, 下一步要如何调整. 将所有的工作分类, 不同的工作安排不同的优先级和处理方法. 其实这本书除了能了解开发运维、管理相关价值观之外, 同时也能学到些为人处事的方法, 比如主角总会深呼吸或者倒数几秒, 让自己迅速冷静下来, 因为情绪会阻碍正确的决策, 使问题得不到解决. 多看书太重要了, 因为当自己的视角不够高不够广, 而在一条错误的路渐行渐远时, 有人给予正确的提点自然是最好的, 但实际情况是, 那样的概率很小, 相当于两手一摊, 等着“神啊, 告诉我怎么做吧”, 所以就需要自己多主动吸收前人的优秀经验, 反思自己的行为, 不断调整, 或者以此理解自己领导作出的决策. 说实话, 以自己现在的水平, 还不能很好的吸收书中的理念, 后续还得反复研读, 细细咀嚼书中的案例, 还有最重要的, 用到工作和生活中. 最后, 作为一个学生时代就习惯性逃避写作文的人来说, 整理这篇笔记还挺不适应的, 不过, 不熟就多练嘛. If it hurts, do it more often.","link":"","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://yummyisminer.xyz/blog/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"敏捷","slug":"敏捷","permalink":"https://yummyisminer.xyz/blog/tags/%E6%95%8F%E6%8D%B7/"},{"name":"DevOps","slug":"DevOps","permalink":"https://yummyisminer.xyz/blog/tags/DevOps/"}]},{"title":"“砖墙是为了挡住不够渴望的人”","date":"2020-04-13T00:45:43.000Z","path":"/posts/1936ef26/","text":"前言:前一段时间看了兰迪教授的《最后的一课》,当时他已经癌症晚期了,但是整个演讲过程都保持着饱满的精神, 他的幽默感染了在场的人, 时隔十几年, 我这条屏幕外的咸鱼也深受鼓舞. 有句话贯穿了整个演讲, “Brick walls are there for a reason: they let us prove how badly we want things. ” 印象最深刻的一点:他说的一个童年梦想, 就是能像宇航员一样自由漂浮, 体验失重的感觉. 后来他了解到航天局的一个项目, 让大学生提交在一种飞机上做试验的建议, 这是一种关于训练宇航员适应零重力的飞机, 于是他带着他的学生团队提交了一个虚拟现实的建议.他们也因此获得肯尼迪航天中心参加一次飞行的机会. 但是也明文规定了不允许指导老师参与飞行. 于是他仔细阅读项目的所有相关文件, 发现学生可以带一名记者，然后他跟宇航局负责人保证说，他会把这次试验的消息发到各大新闻网站, 并把这次虚拟现实的照片寄给主流媒体的记者. 最后他以记者的身份跟着学生一起参与飞行体验活动了。 可吸收的经验:他的这个经历, 至少有5点值得我学习. 梦想不是随便说说而已, 得有实际的行动, 如果他不是一直关注宇航局的相关消息, 那就不会知道有那个体验项目了, 机会不是从天而降的, 就像中彩票的前提也是得先去买一张票. 任何时候，都不要抱着不可能的想法，不要被负面情绪控制, 要用理性思维, 仔细推敲规则，总会找到漏洞，找到机会。被告知指导老师不能参与飞行, 他没有被负面情绪控制而放弃, 而是仔细阅读相关条例, 理性的分析解决方案. 做任何事的同时也要替别人着想. 他保证把这次试验的消息发到各大新闻网站, 并把这次虚拟现实的照片寄给主流媒体的记者, 这是对宇航局的宣传有益的, 所以能说服宇航局的负责人, 让他以网络记者的身份参与飞行. 学会取舍, 任何事都不能十全十美的, 如果总是既想要这样, 又想要那样, 最后什么都得不到. 兰迪教授为了能参与飞行, 就放弃了指导老师的身份, 选择了他认为更重要的事. “砖墙是为了挡住那些不够渴望的人”, 有点点挫折的时候, 不要只是想着我都这么努力了, 而是得捋清楚自己到底做了哪些事, 哪些对达成目标有用的, 哪些是无效的, 还有没有别的可行方案, 然后去尝试. 他对体验漂浮的渴望, 让他做到了以上5点(当然不止这些), 最后实现了他童年的梦想. 其实，我有时候也能做到第2点，不过看了他的分享后，我会意识到这是非常好的做法，然后强化这一习惯, 而其他几点就要开始培养了..","link":"","tags":[{"name":"观后感","slug":"观后感","permalink":"https://yummyisminer.xyz/blog/tags/%E8%A7%82%E5%90%8E%E6%84%9F/"}]},{"title":"jmeter分布式压测及问题记录","date":"2020-04-12T12:22:03.000Z","path":"/posts/270d5148/","text":"问题描述: 需要使用jmeter模拟大并发的情况时，单台压测机不能满足需求，可进行分布式压测。 简单来说就是，多台机器同时安装jmeter，选择一台机器作为调度机，其他作为压力机。进行相应的配置后，就可以用调度机操控压力机发起请求。 如何配置（以Windows为例）： 1.压力机： 1）执行当前压力机下jmeter安装包bin目录下的jmeter-server的批处理文件，此时该机器上启动一个java进程，并随机分配端口，监听来自调度机的请求。 但是这里我们需要配置成固定端口方式，否则调度机远程启动压力机时，会报错。 配置固定端口：打开bin目录下的jmeter.properties文件，更改server_port、server.rmi.localport的端口为要配置的端口。 2.调度机： 打开jmeter安装包bin目录下的jmeter.properties文件，更改remote_hosts为，压力机ip及执行jmeter-server后启动的端口。 开始测试： 1.调度机正常配置好要测试的地址、参数、监听器等后，选择远程启动，就可以用刚刚配置好的压力机，进行压测了。 补充Linux上的配置： 1、启动slave server 命令：jmeter-server -Djava.rmi.sver.hostname=192.168.0.64 遇到的问题及解决：问题一： jmeter4.0，启动slave报错 “java.io.FileNotFoundException: rmi_keystore.jks (没有那个文件或目录)” 解决： 方法一：slave的jmeter.properties中，设置“server.rmi.ssl.disable=true” 原因：jmeter4.0以上的版本，默认启用RMI连接的安全通信，需要创建密钥库。所以将SSL禁用即可。 方法二：手动生成秘钥和证书。执行create-rmi-keystore.bat（Windows适用）或create-rmi-keystore.sh（Linux适用） 问题二： 调度机远程调用slave时，连接超时。查看slave上的jmeter-server.log，发现是与调度机的虚拟机网卡连接超时。 解决：在调度机的jmeter.bat中修改配置指定客户端的网卡ip. 增加配置项：set rmi_host=-Djava.rmi.server.hostname=xxx.xxx.xxx.xxx 修改配置项：set ARGS=%DUMP% %HEAP% %NEW% %SURVIVOR% %TENURING% %PERM% %CLASS_UNLOAD% %DDRAW% %rmi_host% 注意事项：1、master、slave的时间要同步，否则tps结果误差较大。 同步时间的命令：123456# Windows下：w32tm /config /manualpeerlist:\"time.windows.com\" /syncfromflags:manual /reliable:yes /update# Linux下：ntpdate time.windows.com 参考资料1参考资料2参考资料3参考资料4参考资料5参考资料6参考资料7参考资料8","link":"","tags":[{"name":"测试","slug":"测试","permalink":"https://yummyisminer.xyz/blog/tags/%E6%B5%8B%E8%AF%95/"},{"name":"性能测试","slug":"性能测试","permalink":"https://yummyisminer.xyz/blog/tags/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"}]},{"title":"jmeter请求参数化","date":"2020-04-12T10:08:43.000Z","path":"/posts/b8d58d05/","text":"问题一：使用jmeter对下单进行压测的时候，订单号不允许重复，那怎么办呢。 可以采用读取csv文件进行参数化。 具体操作步骤： 1.选中线程组，右键的配置元件就可以看到【CSV 数据文件设置】 2.不重复的订单号有了，在【CSV 数据文件设置】的【变量名称选项】设置变量名，就可以通过${变量名}从配置文件中读取对应的数据。 3.请求中替换相应的变量，使请求与变量及配置文件相互关联。 补充： 1.也可以通过bean shell调用UUID的randomUUID()方法来实现参数化 参考资料 问题二：下单请求，需要MD5加密，怎么解决？ jmeter第三方插件Custom JMeter Functions中有__MD5函数。 如果没有安装插件管理中心, 则先在jmeter 的lib/ext 目录下放插件管理中心 plugins-manager.jar 这个jar包, 然后重启JMeter, 就能使用该函数了 具体用法可以通过【选项】-【函数助手对话框】进行查看。 用添加用户自定义变量的方法，添加加密所需要参数变量，再通过V函数（用法：${V(变量名)} ）获取加密所需要的值。 如果加密字符串还包含变量名，直接在__MD5函数中填写对应的变量名即可 如果还需要对加密后字符串转换成大写，则可以用uppercase转换成大写。 而该方法的实现其实就是继承了AbstractFunction这个抽象类, 然后重写4个方法. 后续如果需要自己添加额外的逻辑, 也可以按照这个方式去实现, 打成jar包后, 放到lib/ext目录下.12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394package kg.apc.jmeter.functions;import org.apache.jmeter.engine.util.CompoundVariable;import org.apache.jmeter.functions.AbstractFunction;import org.apache.jmeter.functions.InvalidVariableException;import org.apache.jmeter.samplers.SampleResult;import org.apache.jmeter.samplers.Sampler;import org.apache.jmeter.threads.JMeterVariables;import org.apache.jorphan.util.JOrphanUtils;import java.security.MessageDigest;import java.security.NoSuchAlgorithmException;import java.util.Collection;import java.util.LinkedList;import java.util.List;public class MD5 extends AbstractFunction { private static final List&lt;String&gt; desc = new LinkedList&lt;String&gt;(); private static final String KEY = \"__MD5\"; static { desc.add(\"String to calculate MD5 hash\"); desc.add(\"Name of variable in which to store the result (optional)\"); } private Object[] values; /** * No-arg constructor. */ public MD5() { } /** * {@inheritDoc} */ @Override public synchronized String execute(SampleResult previousResult, Sampler currentSampler) throws InvalidVariableException { // 获取存放了当前线程的所有变量的一个容器对象 JMeterVariables vars = getVariables(); // 从数组中获取要加密的原始字符串, 强转为CompoundVariable类型后, 通过execute方法转成字符串 String str = ((CompoundVariable) values[0]).execute(); MessageDigest digest; try { digest = MessageDigest.getInstance(\"md5\"); } catch (NoSuchAlgorithmException ex) { return \"Error creating digest: \" + ex; } digest.update(str.getBytes()); byte[] digestArray = digest.digest(); for (byte b: digestArray){ stringBuffer.append(String.format(\"%02x\",b)); } String res = stringBuffer.toString(); if (vars != null &amp;&amp; values.length &gt; 1) { // 把第二个参数(也就是要替换的变量名)作为键, 加密后的结果作为值, 存入到vars容器中 // 后续就可以通过${varName的值}来获取加密后的字符串 String varName = ((CompoundVariable) values[1]).execute().trim(); vars.put(varName, res); } return res; } /** * {@inheritDoc} 解析参数, 并存到数组中, 此时参数的类型是CompoundVariable */ @Override public synchronized void setParameters(Collection&lt;CompoundVariable&gt; parameters) throws InvalidVariableException { checkMinParameterCount(parameters, 1); values = parameters.toArray(); } /** * {@inheritDoc} 函数助手中显示的方法名, 其中__是不显示的 */ @Override public String getReferenceKey() { return KEY; } /** * {@inheritDoc} 参数描述 */ @Override public List&lt;String&gt; getArgumentDesc() { return desc; }} 参考资料1参考资料2","link":"","tags":[{"name":"性能测试","slug":"性能测试","permalink":"https://yummyisminer.xyz/blog/tags/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"}]},{"title":"Dubbo接口框架相关概念","date":"2020-04-12T03:11:30.000Z","path":"/posts/f0c13426/","text":"关于dubbo：why: 为了解决,随着互联网发展,而日益增长的业务复杂度,网站应用规模不断扩大,且常规的垂直应用架构也无法应付,而提出的解决方案. 1. 架构发展角度: 单一应用架构 网站流量很小时,将所有功能都部署在一个应用,节省部署节点和成本.此时,重点是简化增删改查工作量的数据访问框架ORM (图源https://www.jianshu.com/p/92ca0bfbd52f) 单体架构相关资料: 单体架构指应用代码都作为同一个进程,部署和运行在单一节点中. 单一节点服务器中,整体中的所有的模块都组装到单一的内存镜像中,作为一个进程运行在单一节点上. 其中,如果将应用程序部署到多个服务器（如在水平扩展上下文中），它仍然是一个整体。 单体架构参考资料1 单体架构参考资料2 单体架构参考资料3 垂直应用架构 访问量逐渐增大,单一应用增加机器(通过在负载均衡器后端运行多个拷贝，实现多个扩展)带来的加速度越来越小,于是需要将应用拆成互不相干的几个应用来提升效率,此时的重点是用于加速前端页面开发的Web框架(MVC). 分布式服务架构 为了应对增长的业务量,一台机器的性能已经无法满足,需要多台机器才能应对大规模的应用场景,同时也为了提高整个系统架构的可用性,消除单点故障,而垂直或水平拆分业务系统为多个应用. 当垂直应用越来越多,应用之间需要交互,将核心业务抽取出来,作为独立的服务,逐渐形成稳定的服务中心,使前端应用能更快速的响应多变的市场需求.此时,重点是解决进程间通信问题和提高业务复用及整合的分布式服务框架RPC. 流动计算架构 当服务越来越多,容量的评估,小服务资源的浪费等问题逐渐显现,此时需要增加一个调度中心基于访问实时管理集群容量,提高集群利用率.此时,重点是提高机器利用率的资源调度和治理中心SOA. 2. 要解决的问题: 在大规模服务化之前，应用可能只是通过 RMI 或 Hessian 等工具，简单的暴露和引用远程服务，通过配置服务的URL地址进行调用，通过 F5 等硬件进行负载均衡。当服务越来越多时，服务 URL 配置管理变得非常困难，F5 硬件负载均衡器的单点压力也越来越大。 需要服务调用方能自动感知到服务提供方的地址,而对服务提供方进行横向扩展的时候,服务调用方能自动感知到 因此需要一个服务注册中心，动态地注册和发现服务, 通过消费方获取服务提供方地址列表,实现软负载均衡和 Failover，降低对 F5 硬件负载均衡器的依赖，也能减少部分成本。 解决清晰描述错综复杂的服务依赖关系的问题 服务的调用量越来越大，服务的容量问题就暴露出来，这个服务需要多少机器支撑？什么时候该加机器？ 为了解决这些问题，第一步，要将服务现在每天的调用量，响应时间，都统计出来，作为容量规划的参考指标。其次，要可以动态调整权重，在线上，将某台机器的权重一直加大，并在加大的过程中记录响应时间的变化，直到响应时间到达阈值，记录此时的访问量，再以此访问量乘以机器数反推总容量。 what: 一个远程服务调用的分布式框架，调用协议通常包含传输协议和序列化协议。 Dubbo本身支持多种远程调用方式，例如Dubbo RPC（二进制序列化 + tcp协议）、http invoker（二进制序列化 + http协议）、hessian（二进制序列化 + http协议）、WebServices （文本序列化 + http协议）等。 架构说明: 官网介绍地址 1. 节点角色说明 节点 角色说明 Provider 暴露服务的服务提供方 Consumer 调用远程服务的服务消费方 Registry 服务注册与发现的注册中心 Monitor 统计服务的调用次数和调用时间的监控中心 Container 暴露服务的服务提供方 Consumer 服务运行容器 2. 调用关系说明1. 服务容器负责启动，加载，运行服务提供者。 2. 服务提供者在启动时，向注册中心注册自己提供的服务。 3. 服务消费者在启动时，向注册中心订阅自己所需的服务。 4. 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。 5. 服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。 6. 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。管理控制台的编译安装： 新版管理控制台主要的作用：服务查询，服务治理(包括Dubbo2.7中新增的治理规则)以及服务测试、配置管理 步骤:123456789101112131415161718192021222324# 克隆项目到本地，并编译安装和启动（如果是Windows下，则在powershell进行）git clone https://github.com/apache/incubator-dubbo-ops.git# 切到项目根目录cd incubator-dubbo-admin-develop# 编译构建mvn clean package# 修改配置文件，指定注册中心地址dubbo-admin-server/src/main/resources/application-production.properties # 主要的配置有： admin.config-center=zookeeper://127.0.0.1:2181 admin.registry.address=zookeeper://127.0.0.1:2181 admin.metadata-report.address=zookeeper://127.0.0.1:2181# 启动服务cd dubbo-distribution/targetjava -jar dubbo-admin-0.1.jar# 或以下命令启动服务mvn --projects dubbo-admin-server spring-boot:run# 启动完成后，直接访问http://localhost:8080 官方示例地址","link":"","tags":[{"name":"测试","slug":"测试","permalink":"https://yummyisminer.xyz/blog/tags/%E6%B5%8B%E8%AF%95/"},{"name":"接口测试","slug":"接口测试","permalink":"https://yummyisminer.xyz/blog/tags/%E6%8E%A5%E5%8F%A3%E6%B5%8B%E8%AF%95/"}]},{"title":"Dubbo接口测试","date":"2020-04-03T05:30:40.000Z","path":"/posts/81c88605/","text":"接上文,了解Dubbo接口后,如何测试dubbo接口：Python版解决方案:1. hessian+http的方式调用(python-hessian库): (1) dubbo项目中，增加hessian方式序列化，及相关依赖。下图为xml配置方式示例。 官方配置hessian协议及依赖例子 官方配置多协议例子 (2) 获取接口地址（可在管理台查看）、方法及方法的入参。 (3) 安装 python-hessian 1python -m pip install python-hessian (4) 编写Python脚本调用接口; pyhessian官方调用例子 12345678910111213141516171819202122232425262728# coding=utf-8import pytestfrom pyhessian.client import HessianProxyclass TestDubbo(object): url = \"http://169.254.210.145:1234/\" interface = \"com.xxx.user.service.UserService\" full_url = url + interface # full_url = \"http://169.254.210.145:8888/com.xxx.user.service.FileService\" def testsayHelloWithSpec(self): params = u\"什么我调用成功了吗\" # 创建连接对象 service = HessianProxy(self.full_url) # 重载方法__call()__里发送二进制数据进行请求，调用方法 res = service.sayHello(params) assert \"什么我调用成功了吗\" in res print(res) # @pytest.mark.skip() def testsayHelloWithInt(self): params = 123 service = HessianProxy(self.full_url) res = service.sayHello(params) assert 123 in res print(res)if __name__ == \"__main__\": pytest.main([\"-q\",\"TestDubbo.py\"]) 2. 使用dubbo-client dubbo项目中，provicer.xml 增加 jsonrpc 协议 官方地址其他参考示例 123456789101112131415161718config = ApplicationConfig('test_rpclib')service_interface = 'com.ofpay.demo.api.UserProvider'# Contains a connection to zookeeper, which needs caching.registry = ZookeeperRegistry('192.168.59.103:2181', config)user_provider = DubboClient(service_interface, registry, version='1.0')for i in range(1000): try: print user_provider.getUser('A003') print user_provider.queryUser( {u'age': 18, u'time': 1428463514153, u'sex': u'MAN', u'id': u'A003', u'name': u'zhangsan'}) print user_provider.queryAll() print user_provider.isLimit('MAN', 'Joe') print user_provider('getUser', 'A005') except DubboClientError, client_error: print client_error time.sleep(5) java:1. XML配置文件方式: 拿到服务的jar包或maven依赖 在resources下创建consumer.xml,配置好注册中心地址,接口名全称(有包名限定),每个接口有其唯一的标识reference id 调用测试方法中,使用springframework提供的方法加载consumer.xml配置文件,得到context对象,调用start方法启动 调用context对象的getBean方法,传入接口标识作为实参,获取接口的具体实现对象,这步会进行远程过程调用 通过获取的对象调用其提供的方法 12345678910111213141516171819202122232425262728293031import com.xxx.user.service.UserService;import org.junit.BeforeClass;import org.junit.Test;import org.springframework.context.support.ClassPathXmlApplicationContext;import static org.hamcrest.CoreMatchers.containsString;import static org.junit.Assert.assertThat;public class ConsumerTest { static ClassPathXmlApplicationContext context; static UserService userService; @BeforeClass public static void beforeClass(){ if(context==null) { // 默认从类路径中加载配置文件 context = new ClassPathXmlApplicationContext(\"consumer.xml\"); System.out.println(\"load\"); // 在Spring中还提供了Lifecycle接口，Lifecycle中包含start/stop方法，实现此接口后Spring保证在启动的时候调用其start方法开始生命周期,主要用于控制异步处理过程 context.start();// System.out.println(\"start\"); } // 创建接口实例（定义接口的引用变量，再引用实现了该接口的实例） userService=(UserService) context.getBean(\"userService\"); } @Test public void consumerTestCase1(){ // 调用方法 String hello = userService.sayHello(\"world\"); assertThat(hello,containsString(\"world\"); System.out.println(hello); } } 2. API方式的泛化调用: 不需要获取被测接口的jar包或依赖 官方示例1 官方示例2 创建连接实例: 使用 org.apache.dubbo.config.ApplicationConfig 配置消费者应用名 使用 org.apache.dubbo.config.ReferenceConfig; 创建reference配置实例,设置接口全类名,声明泛化调用,配置消费者 使用org.apache.dubbo.config.RegistryConfig; 配置注册中心地址 调用reference配置实例的get方法,获取GenericService类型的连接实例 调用服务提供的方法: 调用org.apache.dubbo.rpc.service.GenericService 这个接口名为 $invoke方法，它接受三个参数，分别为方法名、方法参数类型数组和参数值数组； 对于方法参数类型数组: 如果是基本类型，如 int 或 long，可以使用 int.class.getName()获取其类型； 如果是基本类型数组，如 int[]，则可以使用 int[].class.getName()； 如果是 POJO，则直接使用全类名，如 com.alibaba.dubbo.samples.generic.api.Params。 参数值数组: 如果是POJO,则转成Map,再将转换后的Map作为参数传入123456789101112131415161718192021222324@Testpublic void test2(){ ApplicationConfig application = new ApplicationConfig(); application.setName(\"api-generic-consumer\"); // 使用RegistryConfig,动态配置注册中心地址 RegistryConfig registry = new RegistryConfig(); registry.setAddress(\"zookeeper://127.0.0.1:2181\"); application.setRegistry(registry); ReferenceConfig&lt;GenericService&gt; reference = new ReferenceConfig&lt;GenericService&gt;(); // 弱类型接口名 reference.setInterface(\"com.ymxdclass.user.service.UserService\"); // 声明为泛化接口 reference.setGeneric(true); reference.setApplication(application); // 用com.alibaba.dubbo.rpc.service.GenericService可以替代所有接口引用 GenericService genericService = reference.get(); String name = (String) genericService.$invoke(\"sayHello\", new String[]{String.class.getName()}, new Object[]{\"who am i\"}); System.out.println(name);}","link":"","tags":[{"name":"测试","slug":"测试","permalink":"https://yummyisminer.xyz/blog/tags/%E6%B5%8B%E8%AF%95/"},{"name":"接口测试","slug":"接口测试","permalink":"https://yummyisminer.xyz/blog/tags/%E6%8E%A5%E5%8F%A3%E6%B5%8B%E8%AF%95/"}]},{"title":"ym","date":"2020-03-12T08:00:33.000Z","path":"/posts/8c27cda5/","text":"欢迎访问需要您重点注意的! 哈哈~","link":"","tags":[]}]